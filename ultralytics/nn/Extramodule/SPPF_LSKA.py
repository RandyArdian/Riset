{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n",
    "    \"\"\"Pad to 'same' shape outputs.\"\"\"\n",
    "    if d > 1:\n",
    "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n",
    "\n",
    "    #default_act = nn.SiLU()  # default activation\n",
    "\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n",
    "        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act =  nn.SiLU() if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def forward_fuse(self, x):\n",
    "        \"\"\"Perform transposed convolution of 2D data.\"\"\"\n",
    "        return self.act(self.conv(x))\n",
    "    \n",
    "class LSKA(nn.Module):\n",
    "    # Large-Separable-Kernel-Attention\n",
    "    # https://github.com/StevenLauHKHK/Large-Separable-Kernel-Attention/tree/main\n",
    "    def _init_(self, dim, k_size=7):\n",
    "        super()._init_()\n",
    "\n",
    "        self.k_size = k_size\n",
    "\n",
    "        if k_size == 7:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 3), stride=(1,1), padding=(0,(3-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(3, 1), stride=(1,1), padding=((3-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 3), stride=(1,1), padding=(0,2), groups=dim, dilation=2)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(3, 1), stride=(1,1), padding=(2,0), groups=dim, dilation=2)\n",
    "        elif k_size == 11:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 3), stride=(1,1), padding=(0,(3-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(3, 1), stride=(1,1), padding=((3-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 5), stride=(1,1), padding=(0,4), groups=dim, dilation=2)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(5, 1), stride=(1,1), padding=(4,0), groups=dim, dilation=2)\n",
    "        elif k_size == 23:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 5), stride=(1,1), padding=(0,(5-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(5, 1), stride=(1,1), padding=((5-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 7), stride=(1,1), padding=(0,9), groups=dim, dilation=3)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(7, 1), stride=(1,1), padding=(9,0), groups=dim, dilation=3)\n",
    "        elif k_size == 35:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 5), stride=(1,1), padding=(0,(5-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(5, 1), stride=(1,1), padding=((5-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 11), stride=(1,1), padding=(0,15), groups=dim, dilation=3)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(11, 1), stride=(1,1), padding=(15,0), groups=dim, dilation=3)\n",
    "        elif k_size == 41:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 5), stride=(1,1), padding=(0,(5-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(5, 1), stride=(1,1), padding=((5-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 13), stride=(1,1), padding=(0,18), groups=dim, dilation=3)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(13, 1), stride=(1,1), padding=(18,0), groups=dim, dilation=3)\n",
    "        elif k_size == 53:\n",
    "            self.conv0h = nn.Conv2d(dim, dim, kernel_size=(1, 5), stride=(1,1), padding=(0,(5-1)//2), groups=dim)\n",
    "            self.conv0v = nn.Conv2d(dim, dim, kernel_size=(5, 1), stride=(1,1), padding=((5-1)//2,0), groups=dim)\n",
    "            self.conv_spatial_h = nn.Conv2d(dim, dim, kernel_size=(1, 17), stride=(1,1), padding=(0,24), groups=dim, dilation=3)\n",
    "            self.conv_spatial_v = nn.Conv2d(dim, dim, kernel_size=(17, 1), stride=(1,1), padding=(24,0), groups=dim, dilation=3)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.clone()\n",
    "        attn = self.conv0h(x)\n",
    "        attn = self.conv0v(attn)\n",
    "        attn = self.conv_spatial_h(attn)\n",
    "        attn = self.conv_spatial_v(attn)\n",
    "        attn = self.conv1(attn)\n",
    "        return u * attn\n",
    "\n",
    "class SPPF_LSKA(nn.Module):\n",
    "    \"\"\"Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher.\"\"\"\n",
    " \n",
    "    def _init_(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))\n",
    "        super()._init_()\n",
    "        c_ = c1 // 2  # hidden channels\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c_ * 4, c2, 1, 1)\n",
    "        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
    "        self.lska = LSKA(c_ * 4, k_size=11)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through Ghost Convolution block.\"\"\"\n",
    "        x = self.cv1(x)\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        return self.cv2(self.lska(torch.cat((x, y1, y2, self.m(y2)), 1)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
